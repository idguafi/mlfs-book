{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4447764c-218b-441a-ab97-4df4062960d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local environment\n",
      "Added the following directory to the PYTHONPATH: /Users/sambarati/Documents/GitHub/mlfs-book\n",
      "HopsworksSettings initialized!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def is_google_colab() -> bool:\n",
    "    if \"google.colab\" in str(get_ipython()):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def clone_repository() -> None:\n",
    "    !git clone https://github.com/featurestorebook/mlfs-book.git\n",
    "    %cd mlfs-book\n",
    "\n",
    "def install_dependencies() -> None:\n",
    "    !pip install --upgrade uv\n",
    "    !uv pip install --all-extras --system --requirement pyproject.toml\n",
    "\n",
    "if is_google_colab():\n",
    "    clone_repository()\n",
    "    install_dependencies()\n",
    "    root_dir = str(Path().absolute())\n",
    "    print(\"Google Colab environment\")\n",
    "else:\n",
    "    root_dir = Path().absolute()\n",
    "    # Strip ~/notebooks/ccfraud from PYTHON_PATH if notebook started in one of these subdirectories\n",
    "    if root_dir.parts[-1:] == ('airquality',):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    if root_dir.parts[-1:] == ('notebooks',):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    root_dir = str(root_dir) \n",
    "    print(\"Local environment\")\n",
    "\n",
    "# Add the root directory to the `PYTHONPATH` to use the `recsys` Python module from the notebook.\n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)\n",
    "print(f\"Added the following directory to the PYTHONPATH: {root_dir}\")\n",
    "    \n",
    "# Set the environment variables from the file <root_dir>/.env\n",
    "from mlfs import config\n",
    "settings = config.HopsworksSettings(_env_file=f\"{root_dir}/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e46aad",
   "metadata": {},
   "source": [
    "<span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 02: Daily Feature Pipeline for Air Quality (aqicn.org) and weather (openmeteo)</span>\n",
    "\n",
    "## üóíÔ∏è This notebook is divided into the following sections:\n",
    "1. Download and Parse Data\n",
    "2. Feature Group Insertion\n",
    "\n",
    "\n",
    "__This notebook should be scheduled to run daily__\n",
    "\n",
    "In the book, we use a GitHub Action stored here:\n",
    "[.github/workflows/air-quality-daily.yml](https://github.com/featurestorebook/mlfs-book/blob/main/.github/workflows/air-quality-daily.yml)\n",
    "\n",
    "However, you are free to use any Python Orchestration tool to schedule this program to run daily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe638c6",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> üìù Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7de2e93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "from mlfs.airquality import util\n",
    "from mlfs import config\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "952c1037",
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTIPLE_SENSORS = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6081d1",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üåç Get the Sensor URL, Country, City, Street names from Hopsworks </span>\n",
    "\n",
    "__Update the values in the cell below.__\n",
    "\n",
    "__These should be the same values as in notebook 1 - the feature backfill notebook__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70cd57d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-18 00:10:21,913 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-11-18 00:10:21,915 INFO: Initializing external client\n",
      "2025-11-18 00:10:21,915 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "Connection closed.\n",
      "2025-11-18 00:10:21,915 INFO: Initializing external client\n",
      "2025-11-18 00:10:21,915 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-18 00:10:23,525 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1267871\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1267871\n"
     ]
    }
   ],
   "source": [
    "project = hopsworks.login(engine=\"python\")\n",
    "fs = project.get_feature_store() \n",
    "secrets = hopsworks.get_secrets_api()\n",
    "\n",
    "# Try to get API key from environment variable first (GitHub Actions), then Hopsworks secrets\n",
    "AQICN_API_KEY = os.getenv(\"AQICN_API_KEY\")\n",
    "if AQICN_API_KEY is None:\n",
    "    api_key_secret = secrets.get_secret(\"AQICN_API_KEY\")\n",
    "    if api_key_secret is not None:\n",
    "        AQICN_API_KEY = api_key_secret.value\n",
    "    else:\n",
    "        raise ValueError(\"AQICN_API_KEY not found in environment variables or Hopsworks secrets\")\n",
    "\n",
    "today = datetime.date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a469c9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not MULTIPLE_SENSORS:\n",
    "    # Single sensor mode - try environment variables first, then Hopsworks secrets\n",
    "    location_str = os.getenv(\"SENSOR_LOCATION_JSON\")\n",
    "    if location_str is None:\n",
    "        location_str = secrets.get_secret(\"SENSOR_LOCATION_JSON\").value\n",
    "    \n",
    "    location = json.loads(location_str)\n",
    "    country=location['country']\n",
    "    city=location['city']\n",
    "    street=location['street']\n",
    "    aqicn_url=location['aqicn_url']\n",
    "    latitude=location['latitude']\n",
    "    longitude=location['longitude']\n",
    "    location_str\n",
    "else:\n",
    "    # Multiple sensors mode - try environment variables first, then Hopsworks secrets\n",
    "    paris_location_str = os.getenv(\"SENSOR_LOCATION_JSON\")\n",
    "    if paris_location_str is None:\n",
    "        paris_location_str = secrets.get_secret(\"SENSOR_LOCATION_JSON\").value\n",
    "    paris_location = json.loads(paris_location_str)\n",
    "    \n",
    "    birmingham_sensors_str = os.getenv(\"BIRMINGHAM_SENSOR_LOCATIONS\")\n",
    "    if birmingham_sensors_str is None:\n",
    "        # Try old name for backwards compatibility\n",
    "        birmingham_sensors_str = secrets.get_secret(\"BIRMINGHAM_SENSORS_JSON\")\n",
    "        if birmingham_sensors_str is None:\n",
    "            birmingham_sensors_str = secrets.get_secret(\"BIRMINGHAM_SENSOR_LOCATIONS\").value\n",
    "        else:\n",
    "            birmingham_sensors_str = birmingham_sensors_str.value\n",
    "    \n",
    "    birmingham_sensors = json.loads(birmingham_sensors_str)\n",
    "    \n",
    "    all_sensors = [paris_location] + birmingham_sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "809e8a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'country': 'France',\n",
       "  'city': 'Paris',\n",
       "  'street': 'Boulevard Peripherique Est',\n",
       "  'aqicn_url': 'https://api.waqi.info/feed/@3088/',\n",
       "  'latitude': 48.86,\n",
       "  'longitude': 2.32},\n",
       " {'country': 'United Kingdom',\n",
       "  'city': 'Birmingham',\n",
       "  'street': 'Birmingham A4540 Roadside',\n",
       "  'aqicn_url': 'https://api.waqi.info/feed/@10101/',\n",
       "  'latitude': '52.476145',\n",
       "  'longitude': '-1.874978',\n",
       "  'csv_file': 'birmingham-a4540-roadside-air-quality.csv'},\n",
       " {'country': 'United Kingdom',\n",
       "  'city': 'Birmingham',\n",
       "  'street': 'Birmingham Ladywood',\n",
       "  'aqicn_url': 'https://api.waqi.info/feed/@11652/',\n",
       "  'latitude': '52.481346',\n",
       "  'longitude': '-1.918235',\n",
       "  'csv_file': 'birmingham-ladywood-air-quality.csv'},\n",
       " {'country': 'United Kingdom',\n",
       "  'city': 'Birmingham',\n",
       "  'street': 'Coventry Allesley',\n",
       "  'aqicn_url': 'https://api.waqi.info/feed/@8913/',\n",
       "  'latitude': '52.411628',\n",
       "  'longitude': '-1.560189',\n",
       "  'csv_file': 'coventry-allesley-air-quality.csv'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caf9289",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\"> üîÆ Get references to the Feature Groups </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66f5d7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve feature groups\n",
    "air_quality_fg = fs.get_feature_group(\n",
    "    name='air_quality',\n",
    "    version=2,\n",
    ")\n",
    "weather_fg = fs.get_feature_group(\n",
    "    name='weather',\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10b6ce8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7ffa41",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üå´ Retrieve Today's Air Quality data (PM2.5) from the AQI API</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f681af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "if not MULTIPLE_SENSORS:  \n",
    "    aq_today_df = util.get_pm25(aqicn_url, country, city, street, today, AQICN_API_KEY)\n",
    "    aq_today_df\n",
    "else:\n",
    "    todays_values = []\n",
    "    for sensor in all_sensors:\n",
    "        sensor_df = util.get_pm25(sensor['aqicn_url'], sensor['country'], sensor['city'], sensor['street'], today, AQICN_API_KEY)\n",
    "        todays_values.append(sensor_df)\n",
    "    aq_today_df = pd.concat(todays_values, ignore_index=True)\n",
    "    aq_today_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9e24eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 6 columns):\n",
      " #   Column   Non-Null Count  Dtype         \n",
      "---  ------   --------------  -----         \n",
      " 0   pm25     4 non-null      float32       \n",
      " 1   country  4 non-null      object        \n",
      " 2   city     4 non-null      object        \n",
      " 3   street   4 non-null      object        \n",
      " 4   date     4 non-null      datetime64[ns]\n",
      " 5   url      4 non-null      object        \n",
      "dtypes: datetime64[ns](1), float32(1), object(4)\n",
      "memory usage: 308.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "aq_today_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2602467f",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üîÑ Calculate Lagged Features</span>\n",
    "\n",
    "To create the lagged features (pm_25_1_day_lag, pm_25_2_day_lag, pm_25_3_day_lag), we need to fetch the last 3 days of PM2.5 values from the feature group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0fb9cd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not MULTIPLE_SENSORS:\n",
    "    # Fetch the last 3 days of PM2.5 data to calculate lagged features\n",
    "    three_days_ago = today - datetime.timedelta(days=3)\n",
    "\n",
    "    # Read historical data from the feature group (version 2) - FILTER BY CITY AND STREET\n",
    "    historical_aq_df = air_quality_fg.filter(\n",
    "        (air_quality_fg.date >= three_days_ago) & \n",
    "        (air_quality_fg.city == city) & \n",
    "        (air_quality_fg.street == street)\n",
    "    ).read()\n",
    "\n",
    "    # Sort by date to ensure proper ordering\n",
    "    historical_aq_df = historical_aq_df.sort_values(by='date')\n",
    "\n",
    "    # Get the last 3 PM2.5 values (most recent first)\n",
    "    if len(historical_aq_df) >= 3:\n",
    "        pm25_values = historical_aq_df['pm25'].tail(3).values\n",
    "        aq_today_df['pm_25_1_day_lag'] = pm25_values[-1]  # Yesterday\n",
    "        aq_today_df['pm_25_2_day_lag'] = pm25_values[-2]  # 2 days ago\n",
    "        aq_today_df['pm_25_3_day_lag'] = pm25_values[-3]  # 3 days ago\n",
    "    else:\n",
    "        print(f\"Warning: Not enough historical data. Found {len(historical_aq_df)} days, need 3.\")\n",
    "        # Set to None or skip insertion if not enough data\n",
    "        aq_today_df['pm_25_1_day_lag'] = None\n",
    "        aq_today_df['pm_25_2_day_lag'] = None\n",
    "        aq_today_df['pm_25_3_day_lag'] = None\n",
    "\n",
    "    print(f\"Lagged features calculated:\")\n",
    "    print(f\"  1-day lag (yesterday): {aq_today_df['pm_25_1_day_lag'].values[0]}\")\n",
    "    print(f\"  2-day lag: {aq_today_df['pm_25_2_day_lag'].values[0]}\")\n",
    "    print(f\"  3-day lag: {aq_today_df['pm_25_3_day_lag'].values[0]}\")\n",
    "\n",
    "    aq_today_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b01a5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.62s) \n",
      "Warning: Not enough historical data for Paris/Boulevard Peripherique Est. Found 1 days, need 3.\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.62s) \n",
      "Warning: Not enough historical data for Paris/Boulevard Peripherique Est. Found 1 days, need 3.\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.58s) \n",
      "Warning: Not enough historical data for Birmingham/Birmingham A4540 Roadside. Found 1 days, need 3.\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.58s) \n",
      "Warning: Not enough historical data for Birmingham/Birmingham A4540 Roadside. Found 1 days, need 3.\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.61s) \n",
      "Warning: Not enough historical data for Birmingham/Birmingham Ladywood. Found 1 days, need 3.\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.61s) \n",
      "Warning: Not enough historical data for Birmingham/Birmingham Ladywood. Found 1 days, need 3.\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.80s) \n",
      "Warning: Not enough historical data for Birmingham/Coventry Allesley. Found 1 days, need 3.\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.80s) \n",
      "Warning: Not enough historical data for Birmingham/Coventry Allesley. Found 1 days, need 3.\n"
     ]
    }
   ],
   "source": [
    "if MULTIPLE_SENSORS:\n",
    "    three_days_ago = today - datetime.timedelta(days=3)\n",
    "    sensor_dfs = []\n",
    "    \n",
    "    for i, sensor in enumerate(all_sensors):\n",
    "        sensor_city = sensor['city']\n",
    "        sensor_street = sensor['street']\n",
    "        \n",
    "        historical_aq_df = air_quality_fg.filter(\n",
    "            (air_quality_fg.date >= three_days_ago) & \n",
    "            (air_quality_fg.city == sensor_city) & \n",
    "            (air_quality_fg.street == sensor_street)\n",
    "        ).read()\n",
    "        \n",
    "        historical_aq_df = historical_aq_df.sort_values(by='date')\n",
    "        \n",
    "        sensor_today = aq_today_df.iloc[[i]].copy()\n",
    "        \n",
    "        if len(historical_aq_df) >= 3:\n",
    "            pm25_values = historical_aq_df['pm25'].tail(3).values\n",
    "            sensor_today['pm_25_1_day_lag'] = pm25_values[-1]\n",
    "            sensor_today['pm_25_2_day_lag'] = pm25_values[-2]\n",
    "            sensor_today['pm_25_3_day_lag'] = pm25_values[-3]\n",
    "        else:\n",
    "            print(f\"Warning: Not enough historical data for {sensor_city}/{sensor_street}. Found {len(historical_aq_df)} days, need 3.\")\n",
    "            sensor_today['pm_25_1_day_lag'] = None\n",
    "            sensor_today['pm_25_2_day_lag'] = None\n",
    "            sensor_today['pm_25_3_day_lag'] = None\n",
    "        \n",
    "        sensor_dfs.append(sensor_today)\n",
    "    \n",
    "    aq_today_df = pd.concat(sensor_dfs, ignore_index=True)\n",
    "    aq_today_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af845ab6",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üå¶ Get Weather Forecast data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d2ecb3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates 48.75¬∞N 2.25¬∞E\n",
      "Elevation 46.0 m asl\n",
      "Timezone None None\n",
      "Timezone difference to GMT+0 0 s\n",
      "Coordinates 52.5¬∞N -1.75¬∞E\n",
      "Elevation 108.0 m asl\n",
      "Timezone None None\n",
      "Timezone difference to GMT+0 0 s\n"
     ]
    }
   ],
   "source": [
    "if not MULTIPLE_SENSORS:\n",
    "    hourly_df = util.get_hourly_weather_forecast(city, latitude, longitude)\n",
    "    hourly_df = hourly_df.set_index('date')\n",
    "    daily_df = hourly_df.between_time('11:59', '12:01')\n",
    "    daily_df = daily_df.reset_index()\n",
    "    daily_df['date'] = pd.to_datetime(daily_df['date']).dt.date\n",
    "    daily_df['date'] = pd.to_datetime(daily_df['date'])\n",
    "    daily_df['city'] = city\n",
    "    daily_df\n",
    "else:\n",
    "    unique_cities = {}\n",
    "    for sensor in all_sensors:\n",
    "        sensor_city = sensor['city']\n",
    "        if sensor_city not in unique_cities:\n",
    "            unique_cities[sensor_city] = {\n",
    "                'latitude': sensor['latitude'],\n",
    "                'longitude': sensor['longitude']\n",
    "            }\n",
    "    \n",
    "    weather_dfs = []\n",
    "    for city_name, coords in unique_cities.items():\n",
    "        hourly_df = util.get_hourly_weather_forecast(city_name, coords['latitude'], coords['longitude'])\n",
    "        hourly_df = hourly_df.set_index('date')\n",
    "        daily_city_df = hourly_df.between_time('11:59', '12:01')\n",
    "        daily_city_df = daily_city_df.reset_index()\n",
    "        daily_city_df['date'] = pd.to_datetime(daily_city_df['date']).dt.date\n",
    "        daily_city_df['date'] = pd.to_datetime(daily_city_df['date'])\n",
    "        daily_city_df['city'] = city_name\n",
    "        weather_dfs.append(daily_city_df)\n",
    "    \n",
    "    daily_df = pd.concat(weather_dfs, ignore_index=True)\n",
    "    daily_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c563109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14 entries, 0 to 13\n",
      "Data columns (total 6 columns):\n",
      " #   Column                       Non-Null Count  Dtype         \n",
      "---  ------                       --------------  -----         \n",
      " 0   date                         14 non-null     datetime64[ns]\n",
      " 1   temperature_2m_mean          14 non-null     float32       \n",
      " 2   precipitation_sum            14 non-null     float32       \n",
      " 3   wind_speed_10m_max           14 non-null     float32       \n",
      " 4   wind_direction_10m_dominant  14 non-null     float32       \n",
      " 5   city                         14 non-null     object        \n",
      "dtypes: datetime64[ns](1), float32(4), object(1)\n",
      "memory usage: 580.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "daily_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1f5008",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style=\"color:#ff5f27;\">‚¨ÜÔ∏è Uploading new data to the Feature Store</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a9de5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-18 00:12:21,357 INFO: \t1 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1267871/fs/1262659/fg/1638064\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1267871/fs/1262659/fg/1638064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 4/4 | Elapsed Time: 00:01 | Remaining Time: 00:00\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: air_quality_2_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1267871/jobs/named/air_quality_2_offline_fg_materialization/executions\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1267871/jobs/named/air_quality_2_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('air_quality_2_offline_fg_materialization', 'SPARK'),\n",
       " {\n",
       "   \"success\": true,\n",
       "   \"results\": [\n",
       "     {\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_min_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"pm25\",\n",
       "           \"min_value\": -0.1,\n",
       "           \"max_value\": 500.0,\n",
       "           \"strict_min\": true\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 735348\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"observed_value\": 42.0,\n",
       "         \"element_count\": 4,\n",
       "         \"missing_count\": null,\n",
       "         \"missing_percent\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2025-11-17T11:12:21.000356Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     }\n",
       "   ],\n",
       "   \"evaluation_parameters\": {},\n",
       "   \"statistics\": {\n",
       "     \"evaluated_expectations\": 1,\n",
       "     \"successful_expectations\": 1,\n",
       "     \"unsuccessful_expectations\": 0,\n",
       "     \"success_percent\": 100.0\n",
       "   },\n",
       "   \"meta\": {\n",
       "     \"great_expectations_version\": \"0.18.12\",\n",
       "     \"expectation_suite_name\": \"aq_expectation_suite\",\n",
       "     \"run_id\": {\n",
       "       \"run_name\": null,\n",
       "       \"run_time\": \"2025-11-18T00:12:21.356950+01:00\"\n",
       "     },\n",
       "     \"batch_kwargs\": {\n",
       "       \"ge_batch_id\": \"deb446f6-c40a-11f0-b1b6-1a0dbb40d079\"\n",
       "     },\n",
       "     \"batch_markers\": {},\n",
       "     \"batch_parameters\": {},\n",
       "     \"validation_time\": \"20251117T231221.356740Z\",\n",
       "     \"expectation_suite_meta\": {\n",
       "       \"great_expectations_version\": \"0.18.12\"\n",
       "     }\n",
       "   }\n",
       " })"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert new data\n",
    "air_quality_fg.insert(aq_today_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d491b0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-18 00:12:35,593 INFO: \t2 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1267871/fs/1262659/fg/1595979\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1267871/fs/1262659/fg/1595979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 14/14 | Elapsed Time: 00:01 | Remaining Time: 00:00\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: weather_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1267871/jobs/named/weather_1_offline_fg_materialization/executions\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1267871/jobs/named/weather_1_offline_fg_materialization/executions\n",
      "2025-11-18 00:12:55,186 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2025-11-18 00:12:55,186 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2025-11-18 00:13:04,864 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2025-11-18 00:13:04,864 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2025-11-18 00:15:01,314 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2025-11-18 00:15:01,314 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2025-11-18 00:15:01,473 INFO: Waiting for log aggregation to finish.\n",
      "2025-11-18 00:15:01,473 INFO: Waiting for log aggregation to finish.\n",
      "2025-11-18 00:15:10,198 INFO: Execution finished successfully.\n",
      "2025-11-18 00:15:10,198 INFO: Execution finished successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('weather_1_offline_fg_materialization', 'SPARK'),\n",
       " {\n",
       "   \"success\": true,\n",
       "   \"results\": [\n",
       "     {\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_min_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"wind_speed_10m_max\",\n",
       "           \"min_value\": -0.1,\n",
       "           \"max_value\": 1000.0,\n",
       "           \"strict_min\": true\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 733221\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"observed_value\": 5.351784706115723,\n",
       "         \"element_count\": 14,\n",
       "         \"missing_count\": null,\n",
       "         \"missing_percent\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2025-11-17T11:12:35.000593Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     },\n",
       "     {\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_min_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"precipitation_sum\",\n",
       "           \"min_value\": -0.1,\n",
       "           \"max_value\": 1000.0,\n",
       "           \"strict_min\": true\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 733220\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"observed_value\": 0.0,\n",
       "         \"element_count\": 14,\n",
       "         \"missing_count\": null,\n",
       "         \"missing_percent\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2025-11-17T11:12:35.000593Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     }\n",
       "   ],\n",
       "   \"evaluation_parameters\": {},\n",
       "   \"statistics\": {\n",
       "     \"evaluated_expectations\": 2,\n",
       "     \"successful_expectations\": 2,\n",
       "     \"unsuccessful_expectations\": 0,\n",
       "     \"success_percent\": 100.0\n",
       "   },\n",
       "   \"meta\": {\n",
       "     \"great_expectations_version\": \"0.18.12\",\n",
       "     \"expectation_suite_name\": \"weather_expectation_suite\",\n",
       "     \"run_id\": {\n",
       "       \"run_name\": null,\n",
       "       \"run_time\": \"2025-11-18T00:12:35.593390+01:00\"\n",
       "     },\n",
       "     \"batch_kwargs\": {\n",
       "       \"ge_batch_id\": \"e730a982-c40a-11f0-b1b6-1a0dbb40d079\"\n",
       "     },\n",
       "     \"batch_markers\": {},\n",
       "     \"batch_parameters\": {},\n",
       "     \"validation_time\": \"20251117T231235.593315Z\",\n",
       "     \"expectation_suite_meta\": {\n",
       "       \"great_expectations_version\": \"0.18.12\"\n",
       "     }\n",
       "   }\n",
       " })"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert new data\n",
    "weather_fg.insert(daily_df, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83e9e2d",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">‚è≠Ô∏è **Next:** Part 03: Training Pipeline\n",
    " </span> \n",
    "\n",
    "In the following notebook you will read from a feature group and create training dataset within the feature store\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
